import torch
import torch.nn as nn
import torch.nn.functional as F
from vae.base import BaseVAE, BaseDecoder, BaseEncoder
from collections import OrderedDict

class CVAEEncoder(BaseEncoder):
    def __init__(self, config: dict):
        '''
            Encoder for the main observation data.
            Encodes the context and current input, so total num of features = seq_len
        '''
        super(CVAEEncoder, self).__init__(config)

        hidden_layer_sizes = config["surface_hidden"]
        seq_len = config["seq_len"]
        feat_dim = config["feat_dim"]
        latent_dim = config["latent_dim"]
        
        encoder_layers = OrderedDict()

        if config["use_dense_surface"]:
            in_feats = seq_len * feat_dim[0] * feat_dim[1]
            encoder_layers["flatten"] = nn.Flatten()
            for i, out_feats in enumerate(hidden_layer_sizes):
                encoder_layers[f"enc_dense_{i}"] = nn.Linear(in_feats, out_feats)
                encoder_layers[f"enc_activation_{i}"] = nn.ReLU()
                in_feats = out_feats
            final_dim = in_feats
        else:
            padding = config["padding"]
            in_feats = seq_len
            for i, out_feats in enumerate(hidden_layer_sizes):
                
                encoder_layers[f"enc_conv_{i}"] = nn.Conv2d(
                    in_feats, out_feats,
                    kernel_size=3, stride=1, padding=padding,
                )
                encoder_layers[f"enc_activation_{i}"] = nn.ReLU()
                in_feats = out_feats
            encoder_layers["flatten"] = nn.Flatten()
            final_dim = in_feats*feat_dim[0]*feat_dim[1]

        self.encoder_layers = nn.Sequential(encoder_layers)
        self.z_mean_layer = nn.Linear(final_dim, latent_dim)
        self.z_log_var_layer = nn.Linear(final_dim, latent_dim)

    def forward(self, x):
        '''
            Input:
                x should be of shape (B,T,H,W), 
                x[:,:context_len,:,:] are the context surfaces (previous days),
                x[:,context_len:,:,:] is the surface to predict
        '''
        x = self.encoder_layers(x) # (B, hidden[-1]xHxW) for conv layers, (B, final_hidden_size) for dense layers
        z_mean = self.z_mean_layer(x)
        z_log_var = self.z_log_var_layer(x)
        eps = torch.rand_like(z_log_var)
        z = z_mean + torch.exp(0.5 * z_log_var) * eps
        return (z_mean, z_log_var, z)

class CVAECtxEncoder(BaseEncoder):
    '''Encoder for the context'''
    def __init__(self, config: dict):
        super(CVAECtxEncoder, self).__init__(config)

        ctx_hidden_layer_sizes = config["ctx_surface_hidden"]
        ctx_len = config["ctx_len"]
        feat_dim = config["feat_dim"]
        ctx_embedding_dim = config["ctx_embedding"]

        # There is no need for distribution sampling
        ctx_encoder_layers = OrderedDict()
        if config["use_dense_surface"]:
            in_feats = ctx_len * feat_dim[0] * feat_dim[1]
            ctx_encoder_layers["flatten"] = nn.Flatten()
            for i, out_feats in enumerate(ctx_hidden_layer_sizes):
                ctx_encoder_layers[f"enc_dense_{i}"] = nn.Linear(in_feats, out_feats)
                ctx_encoder_layers[f"enc_activation_{i}"] = nn.ReLU()
                in_feats = out_feats
            ctx_encoder_layers["ctx_enc_final_linear"] = nn.Linear(in_feats, ctx_embedding_dim)
        else:
            padding = config["padding"]
            in_feats = ctx_len
            for i, out_feats in enumerate(ctx_hidden_layer_sizes):
                ctx_encoder_layers[f"ctx_enc_conv_{i}"] = nn.Conv2d(
                    in_feats, out_feats,
                    kernel_size=3, stride=1, padding=padding,
                )
                ctx_encoder_layers[f"ctx_enc_activation_{i}"] = nn.ReLU()
                in_feats = out_feats
            ctx_encoder_layers["flatten"] = nn.Flatten()
            ctx_encoder_layers["ctx_enc_final_linear"] = nn.Linear(in_feats*feat_dim[0]*feat_dim[1], ctx_embedding_dim)
        self.ctx_encoder_layers = nn.Sequential(ctx_encoder_layers)

    def forward(self, x):
        return self.ctx_encoder_layers(x)

class CVAEDecoder(BaseDecoder):
    def __init__(self, config: dict):
        '''
            Inputs to this module: 1. the latents generated by main encoder on seq_len input. 2. the embedding generated by context encoder on context_len input
            
            Firstly, we try to regenerate the final output of the main encoder using decoder_input layer
            Then, the deconvolution will reconstruct the (B,input_len,H,W) input, where input_len = seq_len-context_len
        '''

        super(CVAEDecoder, self).__init__(config)

        hidden_layer_sizes = config["ctx_surface_hidden"]
        seq_len = config["seq_len"]
        ctx_len = config["ctx_len"]
        feat_dim = config["feat_dim"]
        latent_dim = config["latent_dim"]
        ctx_embedding_dim = config["ctx_embedding"]

        # record the final hidden size for forward function
        in_feats = self.final_hidden_size = hidden_layer_sizes[-1]

        decoder_layers = OrderedDict()
        if config["use_dense_surface"]:
            self.decoder_input = nn.Linear(latent_dim + ctx_embedding_dim, in_feats)

            for i, out_feats in enumerate(reversed(hidden_layer_sizes[:-1])):
                decoder_layers[f"dec_dense_{i}"] = nn.Linear(in_feats, out_feats)
                decoder_layers[f"dec_activation_{i}"] = nn.ReLU()
                in_feats = out_feats
            # transform to the original size
            final_size = (seq_len - ctx_len) * feat_dim[0] * feat_dim[1]
            decoder_layers["dec_final"] = nn.Linear(in_feats, final_size)
            decoder_layers["dec_final_activation"] = nn.ReLU()
            decoder_layers["dec_output"] = nn.Linear(final_size, final_size)
        else:
            padding = config["padding"]
            deconv_output_padding = config["deconv_output_padding"]
            self.decoder_input = nn.Linear(latent_dim + ctx_embedding_dim, in_feats*feat_dim[0]*feat_dim[1])
            for i, out_feats in enumerate(reversed(hidden_layer_sizes[:-1])):
                decoder_layers[f"dec_deconv_{i}"] = nn.ConvTranspose2d(
                    in_feats, out_feats,
                    kernel_size=3, stride=1, padding=padding, output_padding=deconv_output_padding,
                    )
                decoder_layers[f"dec_activation_{i}"] = nn.ReLU()
                in_feats = out_feats
            
            # transform to the original size
            decoder_layers["dec_final"] = nn.ConvTranspose2d(
                in_feats, in_feats,
                kernel_size=3, stride=1, padding=padding, output_padding=deconv_output_padding,
            )
            decoder_layers["dec_final_activation"] = nn.ReLU()
            decoder_layers["dec_output"] = nn.Conv2d(
                in_feats, seq_len - ctx_len,
                kernel_size=3, padding="same"
            )
        self.decoder_layers = nn.Sequential(decoder_layers)
    
    def forward(self, x):
        '''
            Input:
                x should be of shape (B,latent_dim+ctx_embedding_size)
        '''
        feat_dim = self.config["feat_dim"]
        seq_len = self.config["seq_len"]
        ctx_len = self.config["ctx_len"]
        if self.config["use_dense_surface"]:
            x = self.decoder_input(x) # (B,hidden[-1])
            out = self.decoder_layers(x)
            out = out.reshape(-1, seq_len - ctx_len, feat_dim[0], feat_dim[1])
        else:
            x = self.decoder_input(x) # (B,hidden[-1]xHxW)
            x = x.reshape(-1, self.final_hidden_size, feat_dim[0], feat_dim[1])
            out = self.decoder_layers(x) 
        return out

class CVAE(BaseVAE):
    def __init__(self, config: dict):
        '''
            The 2D Convolutional encoding and decoding version of Conditional VAE. 
            The input size should be (B,T,H,W), sequence length T will be used as the initial channel size
            Idea from: https://github.com/AntixK/PyTorch-VAE
            
            Input:
                config: must contain hidden, seq_len, feat_dim, latent_dim, device, kl_weight
                seq_len: the time series sequence length
                ctx_len: the part of the sequence that should be treated as context, for now, we assume seq_len = ctx_len+1
                feat_dim: the feature dimension of each time step, integer if 1D, tuple of integers if 2D
                kl_weight: weight \beta used for loss = RE + \beta * KL
                hidden: hidden layer sizes
                ctx_hidden: the hidden layer sizes for the context encoder (for the convolutional hidden layers)
                ctx_embedding: the final embedding size of the context
                use_dense_surface: whether or not flatten the surface into 1D and use Dense Layers for encoding/decoding (default: False)
        '''
        super(CVAE, self).__init__(config)
        self.check_input(config)
        if not config["use_dense_surface"]:
            # we want to keep the dimensions the same, out_dim = (in_dim - kernel_size + 2*padding) / stride + 1
            # so padding = ((out_dim -1) * stride + kernel_size - in_dim) // 2 where in_dim and out_dim are 5
            stride = 1
            feat_dim = config["feat_dim"]
            padding = ((feat_dim[-1] - 1) * stride + 3 - feat_dim[-1]) // 2
            if ((feat_dim[-1] - 1) * stride + 3 - feat_dim[-1]) % 2 == 1:
                padding += 1
                deconv_output_padding = 1
            else:
                deconv_output_padding = 0
            
            config["padding"] = padding
            config["deconv_output_padding"] = deconv_output_padding

        self.encoder = CVAEEncoder(config)
        self.ctx_encoder = CVAECtxEncoder(config)
        self.decoder = CVAEDecoder(config)
        self.to(self.device)

    def get_surface_given_conditions(self, c: torch.Tensor, z: torch.Tensor=None, mu=0, std=1):
        '''
            Input:
                c: context of shape (B,ctx_len,5,5) or (ctx_len,5,5)
                z: pre-generated latent samples, must be of shape (latent_dim,) or (B,latent_dim), 
                mu, std: if z is not given, will be sampled from mu and std as normal distribution
        '''
        if isinstance(c, dict):
            c = c["surface"]
        if len(c.shape) == 3:
            c = c.unsqueeze(0)
        assert c.shape[1] == self.config["ctx_len"], "context length mismatch"
        if z is not None:
            if len(z.shape) == 1:
                z = z.unsqueeze(0)
            assert z.shape[1] == self.config["latent_dim"], "latent dim mismatch"
        else:
            z = mu + torch.randn((c.shape[0], self.config["latent_dim"])) * std

        ctx_embedding = self.ctx_encoder(c.to(self.device)) # embedded c
        z = z.to(self.device)
        decoder_input = torch.cat([ctx_embedding, z], dim=1)
        reconstruction = self.decoder(decoder_input) # P(x|c,z)
        return reconstruction
    
    def check_input(self, config: dict):
        super().check_input(config)
        for req in ["ctx_len", "surface_hidden", "ctx_surface_hidden", "ctx_embedding"]:
            if req not in config:
                raise ValueError(f"config doesn't contain {req}")
        ctx_len = config["ctx_len"]
        seq_len = config["seq_len"]
        assert ctx_len + 1 == seq_len, "seq len > context_len + 1 is not supported"
        if isinstance(config["surface_hidden"], int):
            config["surface_hidden"] = [config["surface_hidden"]]
        if isinstance(config["ctx_surface_hidden"], int):
            config["ctx_surface_hidden"] = [config["ctx_surface_hidden"]]
        
        if "use_dense_surface" not in config:
            config["use_dense_surface"] = False
    
    def forward(self, x):
        '''
            Input:
                x: tensor, should be either unbatched, (seq_len,5,5) or batched (B,seq_len,5,5)
            Returns:
                a tuple of reconstruction, z_mean, z_log_var, z, 
                where z is sampled from distribution defined by z_mean and z_log_var
        '''
        if len(x.shape) == 3 and x.shape[0] == self.seq_len:
            # unbatched data
            x = x.unsqueeze(0)
        ctx_len = self.config["ctx_len"]
        ctx = x[:, :ctx_len, :, :] # c
        ctx_embedding = self.ctx_encoder(ctx) # embedded c
        z_mean, z_log_var, z = self.encoder(x) # P(z|c,x)

        decoder_input = torch.cat([ctx_embedding, z], dim=1)
        reconstruction = self.decoder(decoder_input) # P(x|c,z)
        return (reconstruction, z_mean, z_log_var, z)

    def train_step(self, x, optimizer: torch.optim.Optimizer):
        '''
            Input:
                x should be either unbatched, (seq_len,5,5) or batched (B,seq_len,5,5)
        '''
        if isinstance(x, dict):
            x = x["surface"]
        if len(x.shape) == 3 and x.shape[0] == self.seq_len:
            # unbatched data
            x = x.unsqueeze(0)
        ctx_len = self.config["ctx_len"]

        optimizer.zero_grad()
        x = x.to(self.device)
        input_x = x[:,ctx_len:, :, :] # x
        reconstruction, z_mean, z_log_var, z = self.forward(x)

        # RE = 1/M \sum_{i=1}^M (x_i - y_i)^2
        reconstruction_error = F.mse_loss(reconstruction, input_x)
        # KL = -1/2 \sum_{i=1}^M (1+log(\sigma_k^2) - \sigma_k^2 - \mu_k^2)
        kl_loss = -0.5 * (1 + z_log_var - torch.exp(z_log_var) - torch.square(z_mean))
        kl_loss = torch.mean(torch.sum(kl_loss, dim=1))
        total_loss = reconstruction_error + self.kl_weight * kl_loss
        total_loss.backward()
        optimizer.step()

        return {
            "loss": total_loss,
            "reconstruction_loss": reconstruction_error,
            "kl_loss": kl_loss,
        }
    
    def test_step(self, x):
        if isinstance(x, dict):
            x = x["surface"]
        if len(x.shape) == 3 and x.shape[0] == self.seq_len:
            # unbatched data
            x = x.unsqueeze(0)
        ctx_len = self.config["ctx_len"]
        x = x.to(self.device)
        input_x = x[:,ctx_len:, :, :] # x
        reconstruction, z_mean, z_log_var, z = self.forward(x)

        # RE = 1/M \sum_{i=1}^M (x_i - y_i)^2
        reconstruction_error = F.mse_loss(reconstruction, input_x)
        # KL = -1/2 \sum_{i=1}^M (1+log(\sigma_k^2) - \sigma_k^2 - \mu_k^2)
        kl_loss = -0.5 * (1 + z_log_var - torch.exp(z_log_var) - torch.square(z_mean))
        kl_loss = torch.mean(torch.sum(kl_loss, dim=1))
        total_loss = reconstruction_error + self.kl_weight * kl_loss

        return {
            "loss": total_loss,
            "reconstruction_loss": reconstruction_error,
            "kl_loss": kl_loss,
        }