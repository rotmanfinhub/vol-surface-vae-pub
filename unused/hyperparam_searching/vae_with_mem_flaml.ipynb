{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from vae.datasets import VolSurfaceExFeatsDataSet\n",
    "from vae.cond_conv_vae_with_mem import CVAEConv2DMem\n",
    "from vae.utils import *\n",
    "import flaml\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"data/vol_surface_with_ret.npz\")\n",
    "vol_surf_data = data[\"surface\"]\n",
    "ret_data = data[\"ret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform model evaluation in terms of the accuracy and f1 score.\n",
    "def model_eval_new(model: BaseVAE, dataloader):\n",
    "    model.eval() # switch to eval model, will turn off randomness like dropout\n",
    "    eval_loss = 0\n",
    "    num_batches = 0\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        try:\n",
    "            batch.to(model.device)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        losses = model.test_step(batch)\n",
    "\n",
    "        eval_loss += losses[\"loss\"].item()\n",
    "        num_batches += 1\n",
    "\n",
    "    return eval_loss / num_batches\n",
    "\n",
    "def train_new(model: BaseVAE, train_dataloader: DataLoader, valid_dataloader: DataLoader, \n",
    "          lr=1e-5, epochs=100, \n",
    "          model_dir=\"./\", file_name=\"vanilla.pt\"):\n",
    "    model.train()\n",
    "    optimizer = opt.AdamW(model.parameters(), lr)\n",
    "    best_dev_loss = np.inf\n",
    "\n",
    "    ## run for the specified number of epochs\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    if \".\" in file_name:\n",
    "        file_prefix = file_name.split(\".\")[0]\n",
    "    else:\n",
    "        file_prefix = file_name\n",
    "    log_file = open(f\"{model_dir}/{file_prefix}-{epochs}-log.txt\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "    print(\"Model config: \", file=log_file)\n",
    "    print(json.dumps(model.config, indent=True), file=log_file)\n",
    "    print(f\"LR: {lr}\", file=log_file)\n",
    "    print(f\"Epochs: {epochs}\", file=log_file)\n",
    "    print(\"\", file=log_file)\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        num_batches = 0\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            try:\n",
    "                batch.to(model.device)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            losses = model.train_step(batch, optimizer)\n",
    "\n",
    "            train_loss += losses[\"loss\"].item()\n",
    "            num_batches += 1\n",
    "\n",
    "        train_loss = train_loss / (num_batches)\n",
    "        \n",
    "        dev_loss = model_eval_new(model, valid_dataloader)\n",
    "\n",
    "        if dev_loss < best_dev_loss:\n",
    "            best_dev_loss = dev_loss\n",
    "            model.save_weights(optimizer, model_dir, file_prefix)\n",
    "\n",
    "        # print(f\"epoch {epoch}: train loss :: {train_loss :.3f}, dev loss :: {dev_loss :.3f}, time elapsed :: {time.time() - epoch_start_time}\")\n",
    "        print(f\"epoch {epoch}: train loss :: {train_loss :.3f}, dev loss :: {dev_loss :.3f}, time elapsed :: {time.time() - epoch_start_time}\", file=log_file)\n",
    "        yield train_loss, dev_loss\n",
    "    # print(f\"training finished, total time :: {time.time() - start_time}\")\n",
    "    print(f\"training finished, total time :: {time.time() - start_time}\", file=log_file)\n",
    "    return train_loss, dev_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wrapper(config):\n",
    "    model_config = {\n",
    "        \"seq_len\": config[\"seq_ctx_len\"][0], \n",
    "        \"feat_dim\": (5, 5),\n",
    "        \"latent_dim\": config[\"latent_dim\"],\n",
    "        \"device\": \"cuda\",\n",
    "        \"kl_weight\": config[\"kl_weight\"],\n",
    "        \"re_feat_weight\": config[\"re_feat_weight\"],\n",
    "        \"surface_hidden\": list(config[\"surface_hidden\"]),\n",
    "        \"ex_feats_dim\": 1,\n",
    "        \"ex_feats_hidden\": None,\n",
    "        \"mem_type\": \"lstm\",\n",
    "        \"mem_hidden\": config[\"mem_hidden\"],\n",
    "        \"mem_layers\": config[\"mem_layers\"],\n",
    "        \"mem_dropout\": config[\"mem_dropout\"],\n",
    "        \"ctx_len\": config[\"seq_ctx_len\"][1], \n",
    "        \"ctx_surface_hidden\": list(config[\"ctx_surface_hidden\"]), \n",
    "        \"ctx_ex_feats_hidden\": None,\n",
    "    }\n",
    "    train_dataset = VolSurfaceExFeatsDataSet(vol_surf_data[:4000], ret_data[:4000], config[\"seq_ctx_len\"][0])\n",
    "    train_dataloader = DataLoader(train_dataset, shuffle=False, batch_size=config[\"batch_size\"])\n",
    "    valid_dataset = VolSurfaceExFeatsDataSet(vol_surf_data[4000:5000], ret_data[4000:5000], config[\"seq_ctx_len\"][0])\n",
    "    valid_dataloader = DataLoader(valid_dataset, shuffle=False, batch_size=config[\"batch_size\"])\n",
    "    test_dataset = VolSurfaceExFeatsDataSet(vol_surf_data[5000:], ret_data[5000:], config[\"seq_ctx_len\"][0])\n",
    "    test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=config[\"batch_size\"])\n",
    "\n",
    "    model = CVAEConv2DMem(model_config)\n",
    "    for train_loss, dev_loss in train_new(model, train_dataloader, valid_dataloader, \n",
    "                                 config[\"lr\"], int(round(config[\"num_epochs\"])), \n",
    "                                 \"models\", \"cond_conv2d_lstm.pt\"):\n",
    "        tune.report(train_loss=train_loss, dev_loss=dev_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surface_hidden_size_sampler():\n",
    "    num_layers = np.random.randint(1, 6)\n",
    "    layers = []\n",
    "    for _ in range(num_layers):\n",
    "        layer_size = np.random.randint(1, 11)\n",
    "        layers.append(int(layer_size))\n",
    "    return tuple(layers)\n",
    "\n",
    "def seq_len_sampler():\n",
    "    # modify this for different choices\n",
    "    seq_len_choices=[2, 5, 7, 10, 30, 90, 180, 252, 365]\n",
    "    seq_len = np.random.choice(seq_len_choices)\n",
    "    ctx_len = np.random.randint(1, seq_len)\n",
    "    return (int(seq_len), int(ctx_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-3),\n",
    "    \"num_epochs\": tune.choice([10, 25, 50, 100]),\n",
    "    \"batch_size\": tune.choice([16, 32, 64]),\n",
    "    \"seq_ctx_len\": tune.sample_from(seq_len_sampler),\n",
    "    \"latent_dim\": tune.randint(1, 1001),\n",
    "    \"re_feat_weight\": tune.loguniform(1, 1000),\n",
    "    \"kl_weight\": tune.uniform(0, 1),\n",
    "    \"surface_hidden\": tune.sample_from(surface_hidden_size_sampler),\n",
    "    \"mem_hidden\": tune.randint(25, 101),\n",
    "    \"mem_layers\": tune.randint(1, 11),\n",
    "    \"mem_dropout\": tune.uniform(0, 1),\n",
    "    \"ctx_surface_hidden\": tune.sample_from(surface_hidden_size_sampler),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-05-07 15:16:06</td></tr>\n",
       "<tr><td>Running for: </td><td>00:06:34.91        </td></tr>\n",
       "<tr><td>Memory:      </td><td>15.5/63.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: -0.09011310632241533 | Iter 1.000: -0.3303760759373929<br>Logical resource usage: 0/20 CPUs, 0/1 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th>ctx_surface_hidden  </th><th style=\"text-align: right;\">  kl_weight</th><th style=\"text-align: right;\">  latent_dim</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  mem_dropout</th><th style=\"text-align: right;\">  mem_hidden</th><th style=\"text-align: right;\">  mem_layers</th><th style=\"text-align: right;\">  num_epochs</th><th style=\"text-align: right;\">  re_feat_weight</th><th>seq_ctx_len  </th><th>surface_hidden  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  dev_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_wrapper_9565f865</td><td>TERMINATED</td><td>127.0.0.1:13716</td><td style=\"text-align: right;\">          16</td><td>(4, 7, 2, 4, 5)     </td><td style=\"text-align: right;\">   0.368659</td><td style=\"text-align: right;\">         648</td><td style=\"text-align: right;\">1.56626e-05</td><td style=\"text-align: right;\">     0.266392</td><td style=\"text-align: right;\">          72</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">         12.2582</td><td>(252, 67)    </td><td>(6, 7)          </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         391.893</td><td style=\"text-align: right;\">     0.12013</td><td style=\"text-align: right;\">  0.077612</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  dev_loss</th><th style=\"text-align: right;\">  train_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_wrapper_9565f865</td><td style=\"text-align: right;\">  0.077612</td><td style=\"text-align: right;\">     0.12013</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 15:16:06,962\tINFO tensorboardx.py:269 -- Removed the following hyperparameter values when logging to tensorboard: {'seq_ctx_len': (252, 67), 'surface_hidden': (6, 7), 'ctx_surface_hidden': (4, 7, 2, 4, 5)}\n",
      "2023-05-07 15:16:06,988\tINFO tune.py:945 -- Total run time: 394.95 seconds (394.91 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_wrapper pid=13716)\u001b[0m [W CUDAGuardImpl.h:46] Warning: CUDA warning: driver shutting down (function uncheckedGetDevice)\n",
      "\u001b[2m\u001b[36m(train_wrapper pid=13716)\u001b[0m [W CUDAGuardImpl.h:62] Warning: CUDA warning: driver shutting down (function uncheckedSetDevice)\n"
     ]
    }
   ],
   "source": [
    "result = flaml.tune.run(\n",
    "    tune.with_parameters(train_wrapper),\n",
    "    config=config,\n",
    "    metric=\"dev_loss\",\n",
    "    mode=\"min\",\n",
    "    low_cost_partial_config={\"num_epochs\": 10},\n",
    "    # max_resource=\n",
    "    scheduler=\"asha\",  # Use asha scheduler to perform early stopping based on intermediate results reported\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": 1},\n",
    "    local_dir=\"test/logs/\",\n",
    "    num_samples=1,\n",
    "    use_ray=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#trials=1\n",
      "Best trial config: {'num_epochs': 10, 'lr': 1.5662610420278313e-05, 'batch_size': 16, 'seq_ctx_len': (252, 67), 'latent_dim': 648, 're_feat_weight': 12.258227733927924, 'kl_weight': 0.36865945026811975, 'surface_hidden': (6, 7), 'mem_hidden': 72, 'mem_layers': 8, 'mem_dropout': 0.26639242043080236, 'ctx_surface_hidden': (4, 7, 2, 4, 5)}\n"
     ]
    }
   ],
   "source": [
    "print(f\"#trials={len(result.trials)}\")\n",
    "best_trial = result.get_best_trial(\"loss\", \"dev_loss\", \"all\")\n",
    "print(\"Best trial config: {}\".format(best_trial.config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
